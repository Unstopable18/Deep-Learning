{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation\n",
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  lpa\n",
       "0     8              8    4\n",
       "1     7              9    5\n",
       "2     6             10    6\n",
       "3     5             12    7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]], columns=['cgpa', 'profile_score', 'lpa'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)         \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.ones((layer_dims[l-1], layer_dims[l]))*0.1\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "    return parameters\n",
    "    \n",
    "def linear_forward(A_prev, W, b):\n",
    "    Z = np.dot(W.T, A_prev) + b\n",
    "    return Z\n",
    "    \n",
    "def L_layer_forward(X, parameters):\n",
    "    A = X\n",
    "    L = len(parameters) // 2  # number of layers in the neural network   \n",
    "    for l in range(1, L+1):\n",
    "        A_prev = A \n",
    "        Wl = parameters['W' + str(l)]\n",
    "        bl = parameters['b' + str(l)]\n",
    "        #print(\"A\"+str(l-1)+\": \", A_prev)\n",
    "        #print(\"W\"+str(l)+\": \", Wl)\n",
    "        #print(\"b\"+str(l)+\": \", bl)\n",
    "        #print(\"--\"*20)\n",
    "        A = linear_forward(A_prev, Wl, bl)\n",
    "        #print(\"A\"+str(l)+\": \", A)\n",
    "        #print(\"**\"*20)           \n",
    "    return A,A_prev\n",
    "\n",
    "def update_parameters(parameters,y,y_hat,A1,X):\n",
    "    parameters['W2'][0][0] = parameters['W2'][0][0] + (0.001 * 2 * (y - y_hat)*A1[0][0])\n",
    "    parameters['W2'][1][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat)*A1[1][0])\n",
    "    parameters['b2'][0][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat))\n",
    "\n",
    "    parameters['W1'][0][0] = parameters['W1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[0][0])\n",
    "    parameters['W1'][0][1] = parameters['W1'][0][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[1][0])\n",
    "    parameters['b1'][0][0] = parameters['b1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0])\n",
    "\n",
    "    parameters['W1'][1][0] = parameters['W1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[0][0])\n",
    "    parameters['W1'][1][1] = parameters['W1'][1][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[1][0])\n",
    "    parameters['b1'][1][0] = parameters['b1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -  1 Loss -  25.321744156025517\n",
      "Epoch -  2 Loss -  18.320004165722047\n",
      "Epoch -  3 Loss -  9.473661050729628\n",
      "Epoch -  4 Loss -  3.2520938634031613\n",
      "Epoch -  5 Loss -  1.3407132589299962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.26507636, 0.38558861],\n",
       "        [0.27800387, 0.40980287]]),\n",
       " 'b1': array([[0.02749056],\n",
       "        [0.02974394]]),\n",
       " 'W2': array([[0.41165744],\n",
       "        [0.48302736]]),\n",
       " 'b2': array([[0.48646246]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs implementation\n",
    "\n",
    "# Parameter initialization\n",
    "#here, [2,2,1]=[no of features Entry,Activation layer 1 nodes,output layer nodes]\n",
    "#------------------> (since, here we have only one hidden layer = Activation layer 1)\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "  Loss = []\n",
    "\n",
    "  for j in range(df.shape[0]):\n",
    "\n",
    "    X = df[['cgpa', 'profile_score']].values[j].reshape(2,1) #Shape(no of features, no. of training example)\n",
    "    y = df[['lpa']].values[j][0]\n",
    "\n",
    "    y_hat,A1 = L_layer_forward(X,parameters) #Forward Propagation\n",
    "    y_hat = y_hat[0][0] #Get y_hat value\n",
    "\n",
    "    update_parameters(parameters,y,y_hat,A1,X) #Gradient Descent to update weights and biases\n",
    "\n",
    "    Loss.append((y-y_hat)**2) #Calculate loss MSE\n",
    "\n",
    "  print('Epoch - ',i+1,'Loss - ',np.array(Loss).mean()) #Calculate Avg loss for epoch\n",
    "\n",
    "parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(2,activation='linear',input_dim=2))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.129933  , -0.83946884],\n",
       "        [-1.1394371 , -0.83429044]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[-0.29577208],\n",
       "        [ 0.5704421 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights([np.array([[0.1 ,  0.1 ],\n",
    "        [ 0.1, 0.1 ]], dtype='float32'),\n",
    " np.array([0., 0.], dtype='float32'),\n",
    " np.array([[0.1],\n",
    "        [0.1]], dtype='float32'),\n",
    " np.array([0.], dtype='float32')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 27.8873\n",
      "Epoch 2/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 27.5833\n",
      "Epoch 3/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 27.2353\n",
      "Epoch 4/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 26.9247\n",
      "Epoch 5/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 26.5505\n",
      "Epoch 6/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 26.2174\n",
      "Epoch 7/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 25.8200\n",
      "Epoch 8/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 25.4600\n",
      "Epoch 9/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 25.0667\n",
      "Epoch 10/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 24.6302\n",
      "Epoch 11/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 24.2574\n",
      "Epoch 12/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 23.8000\n",
      "Epoch 13/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 23.4152\n",
      "Epoch 14/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 22.9081\n",
      "Epoch 15/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 22.4647\n",
      "Epoch 16/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 22.0501\n",
      "Epoch 17/75\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 21.5561\n",
      "Epoch 18/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 21.0898\n",
      "Epoch 19/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 20.5336\n",
      "Epoch 20/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 20.1053\n",
      "Epoch 21/75\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.5833\n",
      "Epoch 22/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 19.0928\n",
      "Epoch 23/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 18.5302\n",
      "Epoch 24/75\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 18.0660\n",
      "Epoch 25/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 17.5234\n",
      "Epoch 26/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 16.9925\n",
      "Epoch 27/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 16.4441\n",
      "Epoch 28/75\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.9610\n",
      "Epoch 29/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 15.4041\n",
      "Epoch 30/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 14.8840\n",
      "Epoch 31/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 14.3695\n",
      "Epoch 32/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 13.8567\n",
      "Epoch 33/75\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 13.3076\n",
      "Epoch 34/75\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 12.8142\n",
      "Epoch 35/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 12.2889\n",
      "Epoch 36/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 11.8417\n",
      "Epoch 37/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 11.3277\n",
      "Epoch 38/75\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.8444\n",
      "Epoch 39/75\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 10.3160\n",
      "Epoch 40/75\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.9234\n",
      "Epoch 41/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.4523\n",
      "Epoch 42/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 8.9501\n",
      "Epoch 43/75\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.5730\n",
      "Epoch 44/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 8.0682\n",
      "Epoch 45/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.6884\n",
      "Epoch 46/75\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.3016\n",
      "Epoch 47/75\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.9287\n",
      "Epoch 48/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6.5456\n",
      "Epoch 49/75\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.2376\n",
      "Epoch 50/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5.8807\n",
      "Epoch 51/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5.5348\n",
      "Epoch 52/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.1590\n",
      "Epoch 53/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.8895\n",
      "Epoch 54/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.6641\n",
      "Epoch 55/75\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.3351\n",
      "Epoch 56/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 4.1093\n",
      "Epoch 57/75\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.8930\n",
      "Epoch 58/75\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.6325\n",
      "Epoch 59/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3837\n",
      "Epoch 60/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.2125\n",
      "Epoch 61/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3.0122\n",
      "Epoch 62/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.8686\n",
      "Epoch 63/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2.7136\n",
      "Epoch 64/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.5069\n",
      "Epoch 65/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.4090\n",
      "Epoch 66/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2.2890\n",
      "Epoch 67/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.1524\n",
      "Epoch 68/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0119\n",
      "Epoch 69/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9346\n",
      "Epoch 70/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8299\n",
      "Epoch 71/75\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.7507\n",
      "Epoch 72/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6856\n",
      "Epoch 73/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6347\n",
      "Epoch 74/75\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.5629\n",
      "Epoch 75/75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4807\n"
     ]
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']]\n",
    "y = df[['lpa']]\n",
    "history=model.fit(X,y,epochs=75,verbose=1,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.37347668, 0.37347668],\n",
       "        [0.36544046, 0.36544046]], dtype=float32),\n",
       " array([0.2721442, 0.2721442], dtype=float32),\n",
       " array([[0.37275404],\n",
       "        [0.37275404]], dtype=float32),\n",
       " array([0.20465098], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0104a31503cc31c58545096f1de32d3ebd5a8dd5a3ce552d8570e05c0378b4b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
